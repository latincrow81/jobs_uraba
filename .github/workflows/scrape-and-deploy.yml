name: Scrape Jobs & Deploy Dashboard

on:
  schedule:
    # Runs every day at 06:00 UTC
    - cron: "0 6 * * *"
  workflow_dispatch: # Allow manual trigger from the GitHub UI
  push:
    branches:
      - main

permissions:
  contents: read
  pages: write
  id-token: write

# Only one deployment runs at a time; queued runs wait, they don't cancel.
concurrency:
  group: pages
  cancel-in-progress: true

jobs:
  scrape-and-build:
    name: Scrape & generate dashboard
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: pip

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Run scrapers and generate dashboard
        run: python main.py

      - name: Stage dashboard for Pages
        run: |
          mkdir -p _site
          cp dashboard.html _site/index.html

      - name: Upload Pages artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: _site

  deploy:
    name: Deploy to GitHub Pages
    needs: scrape-and-build
    runs-on: ubuntu-latest
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    steps:
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
